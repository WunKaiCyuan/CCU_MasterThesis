import json
import os
import time
import google.generativeai as genai
from datetime import timedelta
import typing_extensions as typing

# --- 1. é…ç½®èˆ‡è·¯å¾‘ ---
GENAI_API_KEY = "API_KEY"
MODEL_NAME = "models/gemini-2.5-flash"
genai.configure(api_key=GENAI_API_KEY)

# è¼¸å…¥
QUESTIONS_PATH = "./output/generated_questions.json"  
SUMMARIES_PATH = "./output/document_summaries.json"
# è¼¸å‡º (æª”åç¬¦åˆä½ çš„ 04 ç³»åˆ—ç¿’æ…£)
OUTPUT_PATH = "./output/retrieval_results_full_llm_scan.json"

# --- 2. Schema å®šç¾© ---
class RelevantDoc(typing.TypedDict):
    doc_id: str
    file_name: str

class RetrievalResponse(typing.TypedDict):
    relevant_docs: list[RelevantDoc] # å„²å­˜åŒ…å« ID èˆ‡ æª”åçš„ç‰©ä»¶

# --- 3. å·¥å…·ç¨‹å¼ ---
def load_json(path):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_json(data, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def main():
    questions = load_json(QUESTIONS_PATH)
    all_summaries = load_json(SUMMARIES_PATH)
    
    # å»ºç«‹ ID åˆ° æª”åçš„å°ç…§è¡¨ï¼Œæ–¹ä¾¿è¼¸å›æ ¼å¼
    id_to_name = {s['doc_id']: s['doc_name'] for s in all_summaries}
    
    final_results = load_json(OUTPUT_PATH)
    done_ids = {r["question_id"] for r in final_results}
    print(f"ğŸ”„ åµæ¸¬åˆ°å·²å®Œæˆ {len(done_ids)} é¡Œï¼Œå‰©é¤˜ {len(questions) - len(done_ids)} é¡Œ...")

    # å»ºç«‹å¿«å–
    summary_context = "\n".join([
        f"ã€ID: {s['doc_id']} | æ¨™é¡Œ: {s['doc_name']}ã€‘\næ‘˜è¦ï¼š{s['summary']}\né—œéµå­—ï¼š{', '.join(s.get('keywords', []))}\n---"
        for s in all_summaries
    ])

    print("ğŸ“‚ å»ºç«‹æ‘˜è¦ç´¢å¼•å¿«å–...")
    cache = genai.caching.CachedContent.create(
        model=MODEL_NAME,
        display_name="ccu_summaries_cache",
        contents=[f"ä»¥ä¸‹æ˜¯ä¸­æ­£å¤§å­¸æ ¡è¦æ‘˜è¦ç´¢å¼•ï¼š\n{summary_context}"],
        ttl=timedelta(hours=1)
    )

    model = genai.GenerativeModel.from_cached_content(
        cached_content=cache,
        generation_config={
            "temperature": 0,
            "response_mime_type": "application/json",
            "response_schema": RetrievalResponse,
        }
    )

    try:
        for item in questions:
            q_id = item["id"]
            query = item["question"]
            if q_id in done_ids:
                continue

            print(f"ğŸ” æ­£åœ¨è™•ç† Q{q_id}: {query[:15]}...")
            
            prompt = f"ä½¿ç”¨è€…å•é¡Œï¼š{query}\nä»»å‹™ï¼šè«‹å¾ç´¢å¼•ä¸­æŒ‘é¸å‡ºæœ€ç›¸é—œçš„ 10 å€‹æ³•è¦ã€‚è«‹ä¾ç›¸é—œç¨‹åº¦ç”±é«˜åˆ°ä½æ’åºã€‚"

            try:
                response = model.generate_content(prompt)
                res_json = json.loads(response.text)
                
                # æ ¼å¼è½‰æ›ï¼Œç¢ºä¿ ID èˆ‡ æª”åæ­£ç¢ºå°æ‡‰
                candidates = []
                for doc in res_json.get("relevant_docs", []):
                    d_id = doc['doc_id']
                    candidates.append({
                        "doc_id": d_id,
                        "file_name": id_to_name.get(d_id, "Unknown")
                    })

                final_results.append({
                    "question_id": q_id,
                    "question": query,
                    "retrieved_candidates": candidates
                })
                
                save_json(final_results, OUTPUT_PATH)
                time.sleep(1) 

            except Exception as e:
                print(f"âŒ Q{q_id} å¤±æ•—: {e}")
                time.sleep(5)
                continue
    finally:
        cache.delete()
        print(f"âœ… ä»»å‹™å®Œæˆï¼çµæœå„²å­˜æ–¼ {OUTPUT_PATH}")

if __name__ == "__main__":
    main()
