import json
import os
import time
import google.generativeai as genai
from datetime import timedelta
from core.document_loader import load_documents
import typing_extensions as typing

# --- 1. å®šç¾© Schema ---
class AuditDetail(typing.TypedDict):
    is_relevant: bool
    evidence_quote: str
    is_sufficient: bool
    ai_reasoning: str

class VerificationResult(typing.TypedDict):
    doc_id: str
    file_name: str
    ai_audit: AuditDetail

class SingleQuestionResponse(typing.TypedDict):
    verification_results: list[VerificationResult]

# --- 2. é…ç½® ---
GENAI_API_KEY = "API_KEY"
MODEL_NAME = "models/gemini-2.5-flash"
genai.configure(api_key=GENAI_API_KEY)

INDEX_PATH = "./output/document_index.json"
DATA_DIR = "/Volumes/Shared/MasterThesis/RAG_Evaluation_Framework/data"
QUESTIONS_PATH = "./output/generated_questions.json"
OUTPUT_PATH = "./output/ai_evidence_report.json"

# --- 3. å·¥å…·ç¨‹å¼ ---
def load_json(path):
    if os.path.exists(path):
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    return []

def save_json(data, path):
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)

def main():
    # è®€å–ç´¢å¼•èˆ‡é¡Œç›®
    index_data = load_json(INDEX_PATH)
    file_map = {doc["file_name"].strip(): doc["doc_id"] for doc in index_data.get("documents", [])}
    questions = load_json(QUESTIONS_PATH)

    # è®€å–ç¾æœ‰çµæœ (æ–·é»çºŒå‚³é—œéµ)
    final_report = load_json(OUTPUT_PATH)
    done_ids = {r["question_id"] for r in final_report}
    print(f"ğŸ”„ åµæ¸¬åˆ°å·²å®Œæˆ {len(done_ids)} é¡Œï¼Œå°‡å¾ä¸‹ä¸€é¡Œé–‹å§‹...")

    # 1. è¼‰å…¥ä¸¦æº–å‚™å¿«å–å…§å®¹ (åƒ…åœ¨æœ‰æ–°é¡Œç›®è¦è·‘æ™‚æ‰åš)
    if len(done_ids) < len(questions):
        print("ğŸ“‚ è¼‰å…¥æ–‡æª”ä¸¦å»ºç«‹å¿«å–...")
        langchain_docs = load_documents(DATA_DIR, clean=True)
        all_contents = []
        for doc in langchain_docs:
            f_name = os.path.basename(doc.metadata.get("source", "")).strip()
            d_id = file_map.get(f_name, "Unknown")
            all_contents.append(f"ã€ID: {d_id} | æª”å: {f_name}ã€‘\n{doc.page_content}\n---")

        cache = genai.caching.CachedContent.create(
            model=MODEL_NAME,
            display_name="golden_dataset_cache",
            contents=all_contents,
            ttl=timedelta(hours=1)
        )

        model = genai.GenerativeModel.from_cached_content(
            cached_content=cache,
            generation_config={
                "temperature": 0,
                "response_mime_type": "application/json",
                "response_schema": SingleQuestionResponse,
            }
        )

        # 2. æ‰¹æ¬¡è©¢å•è¿´åœˆ
        for q_item in questions:
            q_id = q_item["id"]
            if q_id in done_ids:
                continue

            print(f"ğŸ” æ­£åœ¨è™•ç† Q{q_id}: {q_item['question'][:15]}...")
            prompt = f"å•é¡Œï¼š{q_item['question']}\nä»»å‹™ï¼šè«‹æ‰¾å‡ºæ‰€æœ‰ç›¸é—œæ ¡è¦æ–‡ä»¶ä¸¦åˆ†æé—œè¯æ€§ã€‚"

            try:
                response = model.generate_content(prompt)
                res_json = json.loads(response.text)

                final_report.append({
                    "question_id": q_id,
                    "question": q_item["question"],
                    "verification_results": res_json.get("verification_results", []),
                    "expert_final_check": ""
                })
                
                # æ¯é¡Œè·‘å®Œç«‹å³å­˜æª”ï¼Œé˜²æ­¢ç¨‹å¼å´©æ½°
                save_json(final_report, OUTPUT_PATH)
                
            except Exception as e:
                print(f"âŒ Q{q_id} å¤±æ•—: {e}")
                # é‡åˆ°éŒ¯èª¤é€šå¸¸æ˜¯ API é™åˆ¶ï¼Œç¨å¾®ä¼‘æ¯é•·ä¸€é»
                time.sleep(30)
                continue

            time.sleep(5) # æ­£å¸¸é–“éš”

        print(f"âœ… ä»»å‹™å®Œæˆï¼çµæœå„²å­˜æ–¼ {OUTPUT_PATH}")
    else:
        print("âœ¨ æ‰€æœ‰é¡Œç›®çš†å·²å®Œæˆã€‚")

if __name__ == "__main__":
    main()
